{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479eaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from math import log, factorial\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "class NaiveBayesFilter(ClassifierMixin):\n",
    "    '''\n",
    "    A Naive Bayes Classifier that sorts messages in to spam or ham.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Create a table that will allow the filter to evaluate P(H), P(S)\n",
    "        and P(w|C)\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series): training data\n",
    "            y (pd.Series): training labels\n",
    "        '''\n",
    "        #get all of the different sms's and create a dictionary to keep track\n",
    "        phrases = X.str.split()\n",
    "        count_dic = {}\n",
    "\n",
    "        for i in X.index:\n",
    "            #see if each sms is ham or spam\n",
    "            bin_ham = int(y[i] == 'ham')\n",
    "            bin_spam = int(y[i] == 'spam')\n",
    "\n",
    "            for word in phrases[i]:\n",
    "\n",
    "                if word in count_dic:\n",
    "                    #add to an instance of ham or spam for each word\n",
    "                    num_spam, num_ham = count_dic[word]\n",
    "                    count_dic[word] = (num_spam + bin_spam, num_ham + bin_ham)\n",
    "\n",
    "                else:\n",
    "                    #create the entry if the word isn't present\n",
    "                    count_dic[word] = (bin_spam, bin_ham)\n",
    "        \n",
    "        self.data = pd.DataFrame(count_dic, index=['spam', 'ham'])\n",
    "\n",
    "        #get the number of mesages\n",
    "        nmess = y.size\n",
    "        labels = y.value_counts().to_dict()\n",
    "        #get the number of ham and spam \n",
    "        nspam = labels['spam']\n",
    "        nham = labels['ham']\n",
    "\n",
    "        self.prob_spam = nspam/nmess\n",
    "        self.prob_ham = nham/nmess\n",
    "        self.words = list(count_dic.keys())\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Find P(C=k|x) for each x in X and for each class k by computing\n",
    "        P(C=k)P(x|C=k)\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Probability each message is ham, spam\n",
    "                0 column is ham\n",
    "                1 column is spam\n",
    "        '''\n",
    "        prob_matrix = []\n",
    "        #get the different parts of the message\n",
    "        phrases = X.str.split()\n",
    "        \n",
    "\n",
    "        for i in X.index:\n",
    "            spam_likelihood = []\n",
    "            ham_likelihood = []\n",
    "            #get the words present in each phrase and count how many times they appear\n",
    "            these_words = list(set(phrases.loc[i])) \n",
    "            count_dict = {word:0 for word in these_words}\n",
    "\n",
    "            for word in these_words:\n",
    "                count_dict[word] = phrases.loc[i].count(word)\n",
    "            \n",
    "            #use MLE estimation\n",
    "            for word in these_words:\n",
    "                 if word in self.words:\n",
    "                    spam_likelihood.append(self.data.loc['spam',word] / self.data.loc['spam'].sum()**count_dict[word])\n",
    "                    ham_likelihood.append(self.data.loc['ham',word] / self.data.loc['ham'].sum()**count_dict[word])\n",
    "\n",
    "            l_ham = self.prob_ham*np.product(ham_likelihood)\n",
    "            l_spam = self.prob_spam*np.product(spam_likelihood)\n",
    "            prob_matrix.append(np.array([l_ham, l_spam]))\n",
    "        \n",
    "        #create the predicted probabilities matrix\n",
    "        prob_matrix = np.array(prob_matrix)\n",
    "\n",
    "        return prob_matrix\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Use self.predict_proba to assign labels to X,\n",
    "        the label will be a string that is either 'spam' or 'ham'\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "        #create our list of labels\n",
    "        word_class = []\n",
    "\n",
    "        #call our method from the previous problem to get the probabilites\n",
    "        prob_mat = self.predict_proba(X)\n",
    "\n",
    "        #find which case is more likely\n",
    "        for prob in prob_mat.tolist():\n",
    "            if prob[0] >= prob[1]:\n",
    "                word_class.append('ham')\n",
    "            else:\n",
    "                word_class.append('spam')\n",
    "        \n",
    "        return word_class\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        '''\n",
    "        Find ln(P(C=k|x)) for each x in X and for each class k\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Probability each message is ham, spam\n",
    "                0 column is ham\n",
    "                1 column is spam\n",
    "        '''\n",
    "        prob_matrix = []\n",
    "        #get the different parts of the message\n",
    "        phrases = X.str.split()\n",
    "\n",
    "        for i in X.index:\n",
    "            spam_likelihood = []\n",
    "            ham_likelihood = []\n",
    "            #get the unique words in each phrase and count their occurrence\n",
    "            these_words = list(set(phrases.loc[i]))\n",
    "            count_dict = {word:0 for word in these_words}\n",
    "\n",
    "            for word in these_words:\n",
    "                count_dict[word] = phrases.loc[i].count(word)\n",
    "\n",
    "            #use logarithmic MLE estimation \n",
    "            for word in these_words:\n",
    "                 if word in self.words:\n",
    "                    spam_likelihood.append((count_dict[word])*np.log((self.data.loc['spam',word]+1)/(self.data.loc['spam'].sum()+2)))\n",
    "                    ham_likelihood.append((count_dict[word])*np.log((self.data.loc['ham',word]+1)/(self.data.loc['ham'].sum()+2)))\n",
    "            \n",
    "            l_spam = np.sum(spam_likelihood)\n",
    "            l_ham = np.sum(ham_likelihood)\n",
    "            prob_matrix.append(np.array([l_ham, l_spam]))\n",
    "        \n",
    "        #complete our probability matrix\n",
    "        prob_matrix = np.array(prob_matrix)\n",
    "        prob_matrix[:,0] += np.log(self.prob_ham)\n",
    "        prob_matrix[:,1] += np.log(self.prob_spam)\n",
    "\n",
    "        return prob_matrix\n",
    "\n",
    "\n",
    "    def predict_log(self, X):\n",
    "        '''\n",
    "        Use self.predict_log_proba to assign labels to X,\n",
    "        the label will be a string that is either 'spam' or 'ham'\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "        #create our list of labels\n",
    "        word_class = []\n",
    "\n",
    "        #call our method from the previous problem to get the probabilites\n",
    "        prob_mat = self.predict_log_proba(X)\n",
    "\n",
    "        #find which case is more likely\n",
    "        for prob in prob_mat.tolist():\n",
    "            if prob[0] >= prob[1]:\n",
    "                word_class.append('ham')\n",
    "            else:\n",
    "                word_class.append('spam')\n",
    "        \n",
    "        return word_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7160bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonBayesFilter(ClassifierMixin):\n",
    "    '''\n",
    "    A Naive Bayes Classifier that sorts messages in to spam or ham.\n",
    "    This classifier assumes that words are distributed like\n",
    "    Poisson random variables\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Uses bayesian inference to find the poisson rate for each word\n",
    "        found in the training set. For this we will use the formulation\n",
    "        of l = rt since we have variable message lengths.\n",
    "\n",
    "        This method creates a tool that will allow the filter to\n",
    "        evaluate P(H), P(S), and P(w|C)\n",
    "\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series): training data\n",
    "            y (pd.Series): training labels\n",
    "\n",
    "        Returns:\n",
    "            self: this is an optional method to train\n",
    "        '''\n",
    "\n",
    "        #get all of the different sms's and create a dictionary to keep track\n",
    "        phrases = X.str.split()\n",
    "        count_dic = {}\n",
    "\n",
    "        for i in X.index:\n",
    "            #see if each sms is ham or spam\n",
    "            bin_ham = int(y[i] == 'ham')\n",
    "            bin_spam = int(y[i] == 'spam')\n",
    "\n",
    "            for word in phrases[i]:\n",
    "\n",
    "                if word in count_dic:\n",
    "                    #add to an instance of ham or spam for each word\n",
    "                    num_spam, num_ham = count_dic[word]\n",
    "                    count_dic[word] = (num_spam + bin_spam, num_ham + bin_ham)\n",
    "\n",
    "                else:\n",
    "                    #create the entry if the word isn't present\n",
    "                    count_dic[word] = (bin_spam, bin_ham)\n",
    "        \n",
    "        self.data = pd.DataFrame(count_dic, index=['spam', 'ham'])\n",
    "        \n",
    "        #get the number of mesages\n",
    "        nmess = y.size\n",
    "        labels = y.value_counts().to_dict()\n",
    "        #get the number of ham and spam \n",
    "        nspam = labels['spam']\n",
    "        nham = labels['ham']\n",
    "\n",
    "        self.prob_spam = nspam/nmess\n",
    "        self.prob_ham = nham/nmess\n",
    "\n",
    "        #get the total instances of spam and ham\n",
    "        nhams = self.data.loc['ham'].sum()\n",
    "        nspams = self.data.loc['spam'].sum()\n",
    "\n",
    "        #create our dictionaries for the poisson rates\n",
    "        self.spam_rates = {}\n",
    "        self.ham_rates = {}\n",
    "\n",
    "        #use equation 11.11 to find the rates\n",
    "        for word in self.data.columns:\n",
    "            times_as_ham = self.data.loc['ham', word]\n",
    "            ham_rate = (times_as_ham + 1) / (nhams + 2)\n",
    "            self.ham_rates[word] = ham_rate\n",
    "\n",
    "            times_as_spam = self.data.loc['spam', word]\n",
    "            spam_rate = (times_as_spam + 1) / (nspams + 2)\n",
    "            self.spam_rates[word] = spam_rate\n",
    "\n",
    "        self.words = list(count_dic.keys())\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        '''\n",
    "        Find ln(P(C=k|x)) for each x in X and for each class\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Log probability each message is ham or spam\n",
    "                column 0 is ham, column 1 is spam\n",
    "        '''\n",
    "\n",
    "        prob_matrix = []\n",
    "        #get the different parts of the message\n",
    "        phrases = X.str.split()\n",
    "\n",
    "        for i in X.index:\n",
    "            n = len(phrases.loc[i])\n",
    "            spam_likelihood = []\n",
    "            ham_likelihood = []\n",
    "            #get the unique words in each phrase and count their occurrence\n",
    "            these_words = list(set(phrases.loc[i]))\n",
    "            count_dict = {word:0 for word in these_words}\n",
    "\n",
    "            for word in these_words:\n",
    "                count_dict[word] = phrases.loc[i].count(word)\n",
    "\n",
    "            #use logarithmic MLE estimation with poisson pmf\n",
    "            for word in these_words:\n",
    "                 if word in self.words:\n",
    "                    ham_likelihood.append(np.log(stats.poisson.pmf(count_dict[word],self.ham_rates[word]*n)))\n",
    "                    spam_likelihood.append(np.log(stats.poisson.pmf(count_dict[word],self.spam_rates[word]*n)))\n",
    "            \n",
    "            l_spam = np.sum(spam_likelihood)\n",
    "            l_ham = np.sum(ham_likelihood)\n",
    "            prob_matrix.append(np.array([l_ham, l_spam]))\n",
    "        \n",
    "        #complete our probability matrix\n",
    "        prob_matrix = np.array(prob_matrix)\n",
    "        prob_matrix[:,0] += np.log(self.prob_ham)\n",
    "        prob_matrix[:,1] += np.log(self.prob_spam)\n",
    "\n",
    "        return prob_matrix\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Use self.predict_log_proba to assign labels to X\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "\n",
    "        #create our list of labels\n",
    "        word_class = []\n",
    "\n",
    "        #call our method from the previous problem to get the probabilites\n",
    "        prob_mat = self.predict_log_proba(X)\n",
    "\n",
    "        #find which case is more likely\n",
    "        for prob in prob_mat.tolist():\n",
    "            if prob[0] >= prob[1]:\n",
    "                word_class.append('ham')\n",
    "            else:\n",
    "                word_class.append('spam')\n",
    "        \n",
    "        return word_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f688ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_method(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Use sklearn's methods to transform X_train and X_test, create a\n",
    "    na√Øve Bayes filter, and classify the provided test set.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pandas.Series): messages to train on\n",
    "        y_train (pandas.Series): labels for X_train\n",
    "        X_test  (pandas.Series): messages to classify\n",
    "\n",
    "    Returns:\n",
    "        (ndarray): classification of X_test\n",
    "    '''\n",
    "    #create a dictionary and transform the training data\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    #fit a multinomial nb model\n",
    "    clf = MultinomialNB()\n",
    "    clf = clf.fit(train_counts, y_train)\n",
    "\n",
    "    #transform testing data and classify the data\n",
    "    test_counts = vectorizer.transform(X_test)\n",
    "    labels = clf.predict(test_counts)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46703b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    nbclassifier = NaiveBayesFilter()\n",
    "    nbclassifier.fit(X[:300],y[:300])\n",
    "    assert nbclassifier.data.loc['ham','in'] == 47\n",
    "    assert nbclassifier.data.loc['spam','in'] == 4\n",
    "test_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0662406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_proba():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    nbclassifier = NaiveBayesFilter()\n",
    "    nbclassifier.fit(X[:300],y[:300])\n",
    "    probs = nbclassifier.predict_proba(X[530:535])\n",
    "    true_probs = np.array([[8.33609611e-16, 0.00000000e+00],\n",
    "                            [0.00000000e+00, 2.26874221e-44],\n",
    "                            [0.00000000e+00, 0.00000000e+00],\n",
    "                            [0.00000000e+00, 0.00000000e+00],\n",
    "                            [2.50103642e-10, 0.00000000e+00]])\n",
    "    assert np.allclose(probs,true_probs)\n",
    "test_predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a681973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    nbclassifier = NaiveBayesFilter()\n",
    "    nbclassifier.fit(X[:300],y[:300])\n",
    "    preds = nbclassifier.predict(X[530:535])\n",
    "    truth = np.array(['ham', 'spam', 'ham', 'ham', 'ham'])\n",
    "    assert (preds == truth).all()\n",
    "test_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f363c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_log_proba():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    nbclassifier = NaiveBayesFilter()\n",
    "    nbclassifier.fit(X[:300],y[:300])\n",
    "    probs = nbclassifier.predict_log_proba(X[530:535])\n",
    "    true_probs = np.array([[ -33.39347149,  -35.34710583],\n",
    "                            [-106.83571245,  -93.63509276],\n",
    "                            [ -57.05676356,  -58.34010293],\n",
    "                            [ -19.22723879,  -20.19409107],\n",
    "                            [ -21.5513236 ,  -26.18555562]])\n",
    "    assert np.allclose(probs,true_probs)\n",
    "test_predict_log_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b3d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_log():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    nbclassifier = NaiveBayesFilter()\n",
    "    nbclassifier.fit(X[:300],y[:300])\n",
    "    preds = nbclassifier.predict_log(X[530:535])\n",
    "    truth = np.array(['ham', 'spam', 'ham', 'ham', 'ham'])\n",
    "    assert (preds == truth).all()\n",
    "test_predict_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6511d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_poisson_fit():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    pbclassifier = PoissonBayesFilter()\n",
    "    pbclassifier.fit(X[:300],y[:300])\n",
    "    assert np.isclose(pbclassifier.ham_rates['in'], 0.012588512981904013)\n",
    "    assert np.isclose(pbclassifier.spam_rates['in'],0.004166666666666667)\n",
    "test_poisson_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ff4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_poisson_predict_log_proba():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    pbclassifier = PoissonBayesFilter()\n",
    "    pbclassifier.fit(X[:300],y[:300])\n",
    "    probs = pbclassifier.predict_log_proba(X[530:535])\n",
    "    true_probs = np.array([[-21.42246084, -23.29712325],\n",
    "                            [-58.14578114, -44.50623148],\n",
    "                            [-38.22508624, -39.48322892],\n",
    "                            [-14.45137719, -15.419944  ],\n",
    "                            [-16.23273939, -20.68704484]])\n",
    "    assert np.allclose(probs,true_probs)\n",
    "test_poisson_predict_log_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c15d320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_poisson_predict():\n",
    "    df = pd.read_csv(\"sms_spam_collection.csv\")\n",
    "    X, y = df.Message,df.Label\n",
    "    pbclassifier = PoissonBayesFilter()\n",
    "    pbclassifier.fit(X[:300],y[:300])\n",
    "    preds = pbclassifier.predict(X[530:535])\n",
    "    truth = np.array(['ham', 'spam', 'ham', 'ham', 'ham'])\n",
    "    assert (preds == truth).all()\n",
    "test_poisson_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07de4621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789797487823635\n",
      "0.9797487823634965\n"
     ]
    }
   ],
   "source": [
    "def test_sklearn_method():\n",
    "    df = pd.read_csv('sms_spam_collection.csv')\n",
    "    X, y = df['Message'],df['Label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "\n",
    "    actual_labels = sklearn_method(X_train, y_train, X_test)\n",
    "\n",
    "    nbclassifier = NaiveBayesFilter()\n",
    "    nbclassifier.fit(X_train, y_train)\n",
    "    nbclassifier_labels = nbclassifier.predict_log(X_test)\n",
    "    print(accuracy_score(actual_labels,nbclassifier_labels))\n",
    "\n",
    "    pbclassifier = PoissonBayesFilter()\n",
    "    pbclassifier.fit(X_train,y_train)\n",
    "    pbclassifier_labels = pbclassifier.predict(X_test)\n",
    "    print(accuracy_score(actual_labels,pbclassifier_labels))\n",
    "test_sklearn_method()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
